{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"GROOT: Growing Robust Trees Welcome to the GROOT documentation! Growing Robust Trees (GROOT) is a fast algorithm that fits binary classification decision trees such that they are robust against user-specified adversarial examples. It can be used to fit interpretable robust trees or stronger robust random forests. GROOT closely resembles algorithms used for fitting normal decision trees (i.e. CART) but changes the splitting criterion and the way samples propagate when creating a split. It is based on the algorithm by Chen et al. (2019) but speeds it up tremendously by computing the adversarial Gini impurity in constant time. Get started","title":"Home"},{"location":"#groot-growing-robust-trees","text":"Welcome to the GROOT documentation! Growing Robust Trees (GROOT) is a fast algorithm that fits binary classification decision trees such that they are robust against user-specified adversarial examples. It can be used to fit interpretable robust trees or stronger robust random forests. GROOT closely resembles algorithms used for fitting normal decision trees (i.e. CART) but changes the splitting criterion and the way samples propagate when creating a split. It is based on the algorithm by Chen et al. (2019) but speeds it up tremendously by computing the adversarial Gini impurity in constant time. Get started","title":"GROOT: Growing Robust Trees"},{"location":"getting_started/","text":"The GROOT repository contains several useful modules for fitting and scoring decision trees and ensembles against adversarial examples: Implementations of robust decision tree learning algorithms: GROOT decision tree 1 GROOT random forest 1 TREANT decision tree 2 Provably robust boosting 3 Adversary for attacking and scoring decision trees Kantchelian's MILP attack for attacking and scoring trees / ensembles 4 Easy functions to import datasets Utilities for exporting scikit-learn models 2D decision tree visualizer For an introduction to decision trees and adversarial examples see this blogpost . Installing GROOT can be directly install from PyPi: pip install groot-trees To use Kantchelian's MILP attack it is required that you have GUROBI installed along with their python package: python -m pip install -i https://pypi.gurobi.com gurobipy Toolbox The GROOT toolbox contains the useful Model class which can take models of different types (e.g. Scikit-learn, GROOT, TREANT) and turn these into a general JSON representation. It can also be used to easily evaluate the performance of these models against adversarial attacks. GROOT Example Below is a very simple example demonstrating how to train and score a GROOT tree on a toy dataset. We start by creating a 2D dataset using scikit-learn then split it into a train and test set. from groot.model import GrootTreeClassifier from groot.toolbox import Model from sklearn.datasets import make_moons # Load the dataset X , y = make_moons ( noise = 0.3 , random_state = 0 ) X_test , y_test = make_moons ( noise = 0.3 , random_state = 1 ) To encode an attacker that can increase/decrease a sample by 0.3 for both features we set the attack_model to [0.3, 0.3] . # Define the attacker's capabilities (L-inf norm radius 0.3) epsilon = 0.3 attack_model = [ epsilon , epsilon ] We train the GrootTreeClassifier using .fit() just like other scikit-learn models. # Create and fit a GROOT tree tree = GrootTreeClassifier ( attack_model = attack_model , random_state = 0 ) tree . fit ( X , y ) Lastly, we test the performance. To get the regular accuracy we use .score() and to determine adversarial accuracy we can use the Model class that exposes some useful functionality. # Determine the accuracy and accuracy against attackers accuracy = tree . score ( X_test , y_test ) model = Model . from_groot ( tree ) adversarial_accuracy = model . adversarial_accuracy ( X_test , y_test , attack = \"tree\" , epsilon = 0.3 ) print ( \"Accuracy:\" , accuracy ) print ( \"Adversarial Accuracy:\" , adversarial_accuracy ) See the groot.toolbox for more information on how to use the Model class. Putting it all together The full script is given below. from groot.model import GrootTreeClassifier from groot.toolbox import Model from sklearn.datasets import make_moons # Load the dataset X , y = make_moons ( noise = 0.3 , random_state = 0 ) X_test , y_test = make_moons ( noise = 0.3 , random_state = 1 ) # Define the attacker's capabilities (L-inf norm radius 0.3) epsilon = 0.3 attack_model = [ epsilon , epsilon ] # Create and fit a GROOT tree tree = GrootTreeClassifier ( attack_model = attack_model , random_state = 0 ) tree . fit ( X , y ) # Determine the accuracy and accuracy against attackers accuracy = tree . score ( X_test , y_test ) model = Model . from_groot ( tree ) adversarial_accuracy = model . adversarial_accuracy ( X_test , y_test , attack = \"tree\" , epsilon = 0.3 ) print ( \"Accuracy:\" , accuracy ) print ( \"Adversarial Accuracy:\" , adversarial_accuracy ) Which evaluates to: Accuracy: 0.83 Adversarial Accuracy: 0.65 Vos, Dani\u00ebl, and Sicco Verwer. \"Efficient Training of Robust Decision Trees Against Adversarial Examples.\" arXiv preprint arXiv:2012.10438 (2020). \u21a9 \u21a9 Calzavara, Stefano, et al. \"Treant: training evasion-aware decision trees.\" Data Mining and Knowledge Discovery 34.5 (2020): 1390-1420. \u21a9 Andriushchenko, Maksym, and Matthias Hein. \"Provably robust boosted decision stumps and trees against adversarial attacks.\" arXiv preprint arXiv:1906.03526 (2019). \u21a9 Kantchelian, Alex, J. Doug Tygar, and Anthony Joseph. \"Evasion and hardening of tree ensemble classifiers.\" International Conference on Machine Learning. PMLR, 2016. \u21a9","title":"Getting started"},{"location":"getting_started/#installing","text":"GROOT can be directly install from PyPi: pip install groot-trees To use Kantchelian's MILP attack it is required that you have GUROBI installed along with their python package: python -m pip install -i https://pypi.gurobi.com gurobipy","title":"Installing"},{"location":"getting_started/#toolbox","text":"The GROOT toolbox contains the useful Model class which can take models of different types (e.g. Scikit-learn, GROOT, TREANT) and turn these into a general JSON representation. It can also be used to easily evaluate the performance of these models against adversarial attacks.","title":"Toolbox"},{"location":"getting_started/#groot-example","text":"Below is a very simple example demonstrating how to train and score a GROOT tree on a toy dataset. We start by creating a 2D dataset using scikit-learn then split it into a train and test set. from groot.model import GrootTreeClassifier from groot.toolbox import Model from sklearn.datasets import make_moons # Load the dataset X , y = make_moons ( noise = 0.3 , random_state = 0 ) X_test , y_test = make_moons ( noise = 0.3 , random_state = 1 ) To encode an attacker that can increase/decrease a sample by 0.3 for both features we set the attack_model to [0.3, 0.3] . # Define the attacker's capabilities (L-inf norm radius 0.3) epsilon = 0.3 attack_model = [ epsilon , epsilon ] We train the GrootTreeClassifier using .fit() just like other scikit-learn models. # Create and fit a GROOT tree tree = GrootTreeClassifier ( attack_model = attack_model , random_state = 0 ) tree . fit ( X , y ) Lastly, we test the performance. To get the regular accuracy we use .score() and to determine adversarial accuracy we can use the Model class that exposes some useful functionality. # Determine the accuracy and accuracy against attackers accuracy = tree . score ( X_test , y_test ) model = Model . from_groot ( tree ) adversarial_accuracy = model . adversarial_accuracy ( X_test , y_test , attack = \"tree\" , epsilon = 0.3 ) print ( \"Accuracy:\" , accuracy ) print ( \"Adversarial Accuracy:\" , adversarial_accuracy ) See the groot.toolbox for more information on how to use the Model class.","title":"GROOT Example"},{"location":"getting_started/#putting-it-all-together","text":"The full script is given below. from groot.model import GrootTreeClassifier from groot.toolbox import Model from sklearn.datasets import make_moons # Load the dataset X , y = make_moons ( noise = 0.3 , random_state = 0 ) X_test , y_test = make_moons ( noise = 0.3 , random_state = 1 ) # Define the attacker's capabilities (L-inf norm radius 0.3) epsilon = 0.3 attack_model = [ epsilon , epsilon ] # Create and fit a GROOT tree tree = GrootTreeClassifier ( attack_model = attack_model , random_state = 0 ) tree . fit ( X , y ) # Determine the accuracy and accuracy against attackers accuracy = tree . score ( X_test , y_test ) model = Model . from_groot ( tree ) adversarial_accuracy = model . adversarial_accuracy ( X_test , y_test , attack = \"tree\" , epsilon = 0.3 ) print ( \"Accuracy:\" , accuracy ) print ( \"Adversarial Accuracy:\" , adversarial_accuracy ) Which evaluates to: Accuracy: 0.83 Adversarial Accuracy: 0.65 Vos, Dani\u00ebl, and Sicco Verwer. \"Efficient Training of Robust Decision Trees Against Adversarial Examples.\" arXiv preprint arXiv:2012.10438 (2020). \u21a9 \u21a9 Calzavara, Stefano, et al. \"Treant: training evasion-aware decision trees.\" Data Mining and Knowledge Discovery 34.5 (2020): 1390-1420. \u21a9 Andriushchenko, Maksym, and Matthias Hein. \"Provably robust boosted decision stumps and trees against adversarial attacks.\" arXiv preprint arXiv:1906.03526 (2019). \u21a9 Kantchelian, Alex, J. Doug Tygar, and Anthony Joseph. \"Evasion and hardening of tree ensemble classifiers.\" International Conference on Machine Learning. PMLR, 2016. \u21a9","title":"Putting it all together"},{"location":"license/","text":"MIT License Copyright (c) 2021 Dani\u00ebl Vos Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"License"},{"location":"reference/adversary/","text":"groot.adversary DecisionTreeAdversary Adversary that can attack and score decision trees against adversarial examples. __init__ ( self , decision_tree , kind , attack_model = None , is_numeric = None , n_categories = None , one_adversarial_class = False ) special Parameters: Name Type Description Default decision_tree groot.model.GrootTree or sklearn.tree.DecisionTreeClassifier or groot.treant.RobustDecisionTree The decision tree to attack following our decision tree implementation. required kind {\"ours\", \"groot\", \"sklearn\", \"treant\"} The kind of decision tree to attack, different kinds require different conditions for categorical variables. required attack_model array-like of shape (n_features,) Attacker capabilities for perturbing X, it is only required for when kind is 'sklearn', 'treant' or 'robust'. The attack model describes for every feature in which way it can be perturbed. By default, all features are considered not perturbable. None is_numeric array-like of shape (n_features,) Boolean mask for whether each feature is numerical or categorical. None n_categories array-like of shape (n_features,) Number of categories per feature, entries for numerical features are ignored. None one_adversarial_class bool Whether one class (malicious, 1) perturbs their samples or if both classes (benign and malicious, 0 and 1) do so. False adversarial_accuracy ( self , X , y ) Computes the accuracy under an adversary with given attack model. Parameters: Name Type Description Default X array-like of shape (n_samples, n_features) Test samples. required y array-like of shape (n_samples,) True labels for X. required Returns: Type Description float Adversarial accuracy score. adversarial_f1_score ( self , X , y ) Computes the f1 score under an adversary with given attack model. Parameters: Name Type Description Default X array-like of shape (n_samples, n_features) Test samples. required y array-like of shape (n_samples,) True labels for X. required Returns: Type Description float Adversarial f1 score. average_attack_distance ( self , X , y , order = inf ) Computes the average perturbation distance when perturbing each sample optimally. Here optimally means by the shortest possible distance such that the predicted class is different than the sample's label. The order parameter is fed straight into numpy.linalg.norm. See the numpy documentation for explanations and examples. Parameters: Name Type Description Default X array-like of shape (n_samples, n_features) Test samples. required y array-like of shape (n_samples,) True labels for X. required Returns: Type Description np.float Mean perturbation distance. Leaf Representation of a decision leaf by its bounding box and value. can_reach ( self , point ) Checks whether this leaf is in reach of the given point by the attacker. Parameters: Name Type Description Default point array-like of shape (n_features,) Point's unperturbed values. required Returns: Type Description bool Whether or not the point is in reach of this leaf. compute_intersection ( self , other ) Computes the intersection (a new Leaf object) of this leaf with another leaf. The intersection leaf represents the overlapping region of the two leaves. The new Leaf's value is the average of the original values. Parameters: Name Type Description Default other Leaf Leaf to compute intersection with. required Returns: Type Description Leaf Leaf representing the intersection between this leaf and the other leaf. get_bounding_box ( self ) Get the bounding box of this leaf. Returns: Type Description ndarray of shape (n_features, 2) Bounding box given by [low, high] for each feature. minimal_distance ( self , point , order ) Compute the minimum perturbation distance between this leaf and the given sample in the given L-p norm. Parameters: Name Type Description Default point array-like of shape (n_features,) Point's unperturbed values. required order {0, 1, 2, np.inf} L-p norm to compute distance in. required Returns: Type Description bool Whether or not the point is in reach of this leaf.","title":"Adversaries"},{"location":"reference/adversary/#groot.adversary","text":"","title":"adversary"},{"location":"reference/adversary/#groot.adversary.DecisionTreeAdversary","text":"Adversary that can attack and score decision trees against adversarial examples.","title":"DecisionTreeAdversary"},{"location":"reference/adversary/#groot.adversary.DecisionTreeAdversary.__init__","text":"Parameters: Name Type Description Default decision_tree groot.model.GrootTree or sklearn.tree.DecisionTreeClassifier or groot.treant.RobustDecisionTree The decision tree to attack following our decision tree implementation. required kind {\"ours\", \"groot\", \"sklearn\", \"treant\"} The kind of decision tree to attack, different kinds require different conditions for categorical variables. required attack_model array-like of shape (n_features,) Attacker capabilities for perturbing X, it is only required for when kind is 'sklearn', 'treant' or 'robust'. The attack model describes for every feature in which way it can be perturbed. By default, all features are considered not perturbable. None is_numeric array-like of shape (n_features,) Boolean mask for whether each feature is numerical or categorical. None n_categories array-like of shape (n_features,) Number of categories per feature, entries for numerical features are ignored. None one_adversarial_class bool Whether one class (malicious, 1) perturbs their samples or if both classes (benign and malicious, 0 and 1) do so. False","title":"__init__()"},{"location":"reference/adversary/#groot.adversary.DecisionTreeAdversary.adversarial_accuracy","text":"Computes the accuracy under an adversary with given attack model. Parameters: Name Type Description Default X array-like of shape (n_samples, n_features) Test samples. required y array-like of shape (n_samples,) True labels for X. required Returns: Type Description float Adversarial accuracy score.","title":"adversarial_accuracy()"},{"location":"reference/adversary/#groot.adversary.DecisionTreeAdversary.adversarial_f1_score","text":"Computes the f1 score under an adversary with given attack model. Parameters: Name Type Description Default X array-like of shape (n_samples, n_features) Test samples. required y array-like of shape (n_samples,) True labels for X. required Returns: Type Description float Adversarial f1 score.","title":"adversarial_f1_score()"},{"location":"reference/adversary/#groot.adversary.DecisionTreeAdversary.average_attack_distance","text":"Computes the average perturbation distance when perturbing each sample optimally. Here optimally means by the shortest possible distance such that the predicted class is different than the sample's label. The order parameter is fed straight into numpy.linalg.norm. See the numpy documentation for explanations and examples. Parameters: Name Type Description Default X array-like of shape (n_samples, n_features) Test samples. required y array-like of shape (n_samples,) True labels for X. required Returns: Type Description np.float Mean perturbation distance.","title":"average_attack_distance()"},{"location":"reference/adversary/#groot.adversary.Leaf","text":"Representation of a decision leaf by its bounding box and value.","title":"Leaf"},{"location":"reference/adversary/#groot.adversary.Leaf.can_reach","text":"Checks whether this leaf is in reach of the given point by the attacker. Parameters: Name Type Description Default point array-like of shape (n_features,) Point's unperturbed values. required Returns: Type Description bool Whether or not the point is in reach of this leaf.","title":"can_reach()"},{"location":"reference/adversary/#groot.adversary.Leaf.compute_intersection","text":"Computes the intersection (a new Leaf object) of this leaf with another leaf. The intersection leaf represents the overlapping region of the two leaves. The new Leaf's value is the average of the original values. Parameters: Name Type Description Default other Leaf Leaf to compute intersection with. required Returns: Type Description Leaf Leaf representing the intersection between this leaf and the other leaf.","title":"compute_intersection()"},{"location":"reference/adversary/#groot.adversary.Leaf.get_bounding_box","text":"Get the bounding box of this leaf. Returns: Type Description ndarray of shape (n_features, 2) Bounding box given by [low, high] for each feature.","title":"get_bounding_box()"},{"location":"reference/adversary/#groot.adversary.Leaf.minimal_distance","text":"Compute the minimum perturbation distance between this leaf and the given sample in the given L-p norm. Parameters: Name Type Description Default point array-like of shape (n_features,) Point's unperturbed values. required order {0, 1, 2, np.inf} L-p norm to compute distance in. required Returns: Type Description bool Whether or not the point is in reach of this leaf.","title":"minimal_distance()"},{"location":"reference/datasets/","text":"groot.datasets","title":"Datasets"},{"location":"reference/datasets/#groot.datasets","text":"","title":"datasets"},{"location":"reference/toolbox/","text":"The groot.toolbox package exposes the Model class that allows easy loading, converting and attacking decision tree ensembles of different formats. The Model class can load tree ensembles from the following formats using: Scikit-learn: Model.from_sklearn JSON file: Model.from_json_file GROOT: Model.from_groot TREANT: Model.from_treant Provably robust boosting: Model.from_provably_robust_boosting After loading you can then easily determine metrics such as accuracy and adversarial accuracy (against a given perturbation radius epsilon). It is also possible to get access to more information about adversarial robustness than just a metric. The model class has three methods for this: attack_feasibility : Compute for each sample whether or not an adversarial example exists within an radius around it. attack_distances : Compute for each sample the distance it needs to move to turn into an adversarial example. adversarial_examples : Generate adversarial examples for each input sample. These three methods are theoretically listed in order of increasing complexity. That means that when you only need to know e.g. attack_feasibility and not attack_distances calling only the first function might be faster than calling the second and computing the 'feasibility' from that. For example for the default 'milp' attack, attack_feasibility is orders of magnitude faster than attack_distances and adversarial_examples . Example from sklearn.datasets import load_iris from sklearn.tree import DecisionTreeClassifier from groot.toolbox import Model X , y = load_iris ( return_X_y = True ) tree = DecisionTreeClassifier ( max_depth = 3 ) tree . fit ( X , y ) model = Model . from_sklearn ( tree ) print ( \"Accuracy:\" , model . accuracy ( X , y )) epsilon = 0.3 print ( \"Adversarial accuracy:\" , model . adversarial_accuracy ( X , y , epsilon = epsilon )) X_adv = model . adversarial_examples ( X , y ) print ( \"Adversarial examples:\" ) print ( X_adv ) Code reference groot.toolbox Model __init__ ( self , json_model , n_classes ) special General model class that exposes a common API for evaluating decision tree (ensemble) models. Usually you won't have to call this constructor manually, instead use from_json_file , from_sklearn , from_treant , from_provably_robust_boosting or from_groot . Parameters: Name Type Description Default json_model list of dicts List of decision trees encoded as dicts. See the XGBoost JSON format. required n_classes int Number of classes that this model predicts. required accuracy ( self , X , y ) Determine the accuracy of the model on unperturbed samples. Parameters: Name Type Description Default X array-like of shape (n_samples, n_features) Input samples. required y array-like of shape (n_samples,) True labels. required Returns: Type Description float Accuracy on unperturbed samples. adversarial_accuracy ( self , X , y , attack = 'auto' , order = inf , epsilon = 0.0 , options = {}) Determine the accuracy against adversarial examples within maximum perturbation radius epsilon. Parameters: Name Type Description Default X array-like of shape (n_samples, n_features) Samples to attack. required y array-like of shape (n_samples,) True labels for the samples. required attack {\"auto\", \"milp\", \"tree\"} The attack to use, if \"auto\" the attack is chosen automatically: - \"milp\" for optimal attacks on tree ensembles using a Mixed-Integer Linear Programming formulation. - \"tree\" for optimal attacks on single decision trees by enumerating all possible paths through the tree. 'auto' order {0, 1, 2, inf} L-norm order to use. See numpy documentation of more explanation. inf epsilon float Maximum distance by which samples can move. 0.0 Returns: Type Description float Adversarial accuracy given the maximum perturbation radius epsilon. adversarial_examples ( self , X , y , attack = 'auto' , order = inf , options = {}) Create adversarial examples for each input sample. Parameters: Name Type Description Default X array-like of shape (n_samples, n_features) Samples to attack. required y array-like of shape (n_samples,) True labels for the samples. required attack {\"auto\", \"milp\", \"tree\"} The attack to use, if \"auto\" the attack is chosen automatically: - \"milp\" for optimal attacks on tree ensembles using a Mixed-Integer Linear Programming formulation. - \"tree\" for optimal attacks on single decision trees by enumerating all possible paths through the tree. 'auto' order {0, 1, 2, inf} L-norm order to use. See numpy documentation of more explanation. inf options dict Extra attack-specific options. {} Returns: Type Description ndarray of shape (n_samples, n_features) Adversarial examples. attack_distance ( self , X , y , attack = 'auto' , order = inf , options = {}) Determine the perturbation distance for each sample to make an adversarial example. Parameters: Name Type Description Default X array-like of shape (n_samples, n_features) Samples to attack. required y array-like of shape (n_samples,) True labels for the samples. required attack {\"auto\", \"milp\", \"tree\"} The attack to use, if \"auto\" the attack is chosen automatically: - \"milp\" for optimal attacks on tree ensembles using a Mixed-Integer Linear Programming formulation. - \"tree\" for optimal attacks on single decision trees by enumerating all possible paths through the tree. 'auto' order {0, 1, 2, inf} L-norm order to use. See numpy documentation of more explanation. inf options dict Extra attack-specific options. {} Returns: Type Description ndarray of shape (n_samples,) of floats Distances to create adversarial examples. attack_feasibility ( self , X , y , attack = 'auto' , order = inf , epsilon = 0.0 , options = {}) Determine whether an adversarial example is feasible for each sample given the maximum perturbation radius epsilon. Parameters: Name Type Description Default X array-like of shape (n_samples, n_features) Samples to attack. required y array-like of shape (n_samples,) True labels for the samples. required attack {\"auto\", \"milp\", \"tree\"} The attack to use, if \"auto\" the attack is chosen automatically: - \"milp\" for optimal attacks on tree ensembles using a Mixed-Integer Linear Programming formulation. - \"tree\" for optimal attacks on single decision trees by enumerating all possible paths through the tree. 'auto' order {0, 1, 2, inf} L-norm order to use. See numpy documentation of more explanation. inf epsilon float Maximum distance by which samples can move. 0.0 options dict Extra attack-specific options. {} Returns: Type Description ndarray of shape (n_samples,) of booleans Vector of True/False. Whether an adversarial example is feasible. decision_function ( self , X ) Compute prediction values for some samples. These values are the sum of leaf values in which the samples end up. Parameters: Name Type Description Default X array-like of shape (n_samples, n_features) Samples to predict. required Returns: Type Description ndarray of shape (n_samples) or ndarray of shape (n_samples, n_classes) Predicted values. Returns a 1-dimensional array if n_classes=2, else a 2-dimensional array. from_groot ( classifier ) staticmethod Create a Model instance from a GrootTree, GrootRandomForest or GROOT OneVsRestClassifier. Parameters: Name Type Description Default classifier GrootTree, GrootRandomForest or OneVsRestClassifier (of GROOT models) GROOT model to load. required Returns: Type Description Model Instantiated Model object. from_json_file ( filename , n_classes ) staticmethod Create a Model instance from a JSON file. Parameters: Name Type Description Default filename str Path to JSON file that contains a list of decision trees encoded as dicts. See the XGBoost JSON format. required n_classes int Number of classes that this model predicts. required Returns: Type Description Model Instantiated Model object. from_provably_robust_boosting ( classifier ) staticmethod Create a Model instance from a Provably Robust Boosting TreeEnsemble. Parameters: Name Type Description Default classifier groot.provably_robust_boosting.TreeEnsemble Provably Robust Boosting model to load. required Returns: Type Description Model Instantiated Model object. from_sklearn ( classifier ) staticmethod Create a Model instance from a Scikit-learn classifier. Parameters: Name Type Description Default classifier DecisionTreeClassifier, RandomForestClassifier or GradientBoostingClassifier Scikit-learn model to load. required Returns: Type Description Model Instantiated Model object. from_treant ( classifier ) staticmethod Create a Model instance from a TREANT decision tree. Parameters: Name Type Description Default classifier groot.treant.RobustDecisionTree TREANT model to load. required Returns: Type Description Model Instantiated Model object. predict ( self , X ) Predict classes for some samples. The raw prediction values are turned into class labels. Parameters: Name Type Description Default X array-like of shape (n_samples, n_features) Samples to predict. required Returns: Type Description ndarray of shape (n_samples) Predicted class labels. to_json ( self , filename , indent = 2 ) Export the model object to a JSON file. Parameters: Name Type Description Default filename str Name of the JSON file to export to. required indent int Number of spaces to use for indentation in the JSON file. Can be reduced to save storage. 2","title":"Toolbox"},{"location":"reference/toolbox/#example","text":"from sklearn.datasets import load_iris from sklearn.tree import DecisionTreeClassifier from groot.toolbox import Model X , y = load_iris ( return_X_y = True ) tree = DecisionTreeClassifier ( max_depth = 3 ) tree . fit ( X , y ) model = Model . from_sklearn ( tree ) print ( \"Accuracy:\" , model . accuracy ( X , y )) epsilon = 0.3 print ( \"Adversarial accuracy:\" , model . adversarial_accuracy ( X , y , epsilon = epsilon )) X_adv = model . adversarial_examples ( X , y ) print ( \"Adversarial examples:\" ) print ( X_adv )","title":"Example"},{"location":"reference/toolbox/#code-reference","text":"","title":"Code reference"},{"location":"reference/toolbox/#groot.toolbox","text":"","title":"toolbox"},{"location":"reference/toolbox/#groot.toolbox.Model","text":"","title":"Model"},{"location":"reference/toolbox/#groot.toolbox.Model.__init__","text":"General model class that exposes a common API for evaluating decision tree (ensemble) models. Usually you won't have to call this constructor manually, instead use from_json_file , from_sklearn , from_treant , from_provably_robust_boosting or from_groot . Parameters: Name Type Description Default json_model list of dicts List of decision trees encoded as dicts. See the XGBoost JSON format. required n_classes int Number of classes that this model predicts. required","title":"__init__()"},{"location":"reference/toolbox/#groot.toolbox.Model.accuracy","text":"Determine the accuracy of the model on unperturbed samples. Parameters: Name Type Description Default X array-like of shape (n_samples, n_features) Input samples. required y array-like of shape (n_samples,) True labels. required Returns: Type Description float Accuracy on unperturbed samples.","title":"accuracy()"},{"location":"reference/toolbox/#groot.toolbox.Model.adversarial_accuracy","text":"Determine the accuracy against adversarial examples within maximum perturbation radius epsilon. Parameters: Name Type Description Default X array-like of shape (n_samples, n_features) Samples to attack. required y array-like of shape (n_samples,) True labels for the samples. required attack {\"auto\", \"milp\", \"tree\"} The attack to use, if \"auto\" the attack is chosen automatically: - \"milp\" for optimal attacks on tree ensembles using a Mixed-Integer Linear Programming formulation. - \"tree\" for optimal attacks on single decision trees by enumerating all possible paths through the tree. 'auto' order {0, 1, 2, inf} L-norm order to use. See numpy documentation of more explanation. inf epsilon float Maximum distance by which samples can move. 0.0 Returns: Type Description float Adversarial accuracy given the maximum perturbation radius epsilon.","title":"adversarial_accuracy()"},{"location":"reference/toolbox/#groot.toolbox.Model.adversarial_examples","text":"Create adversarial examples for each input sample. Parameters: Name Type Description Default X array-like of shape (n_samples, n_features) Samples to attack. required y array-like of shape (n_samples,) True labels for the samples. required attack {\"auto\", \"milp\", \"tree\"} The attack to use, if \"auto\" the attack is chosen automatically: - \"milp\" for optimal attacks on tree ensembles using a Mixed-Integer Linear Programming formulation. - \"tree\" for optimal attacks on single decision trees by enumerating all possible paths through the tree. 'auto' order {0, 1, 2, inf} L-norm order to use. See numpy documentation of more explanation. inf options dict Extra attack-specific options. {} Returns: Type Description ndarray of shape (n_samples, n_features) Adversarial examples.","title":"adversarial_examples()"},{"location":"reference/toolbox/#groot.toolbox.Model.attack_distance","text":"Determine the perturbation distance for each sample to make an adversarial example. Parameters: Name Type Description Default X array-like of shape (n_samples, n_features) Samples to attack. required y array-like of shape (n_samples,) True labels for the samples. required attack {\"auto\", \"milp\", \"tree\"} The attack to use, if \"auto\" the attack is chosen automatically: - \"milp\" for optimal attacks on tree ensembles using a Mixed-Integer Linear Programming formulation. - \"tree\" for optimal attacks on single decision trees by enumerating all possible paths through the tree. 'auto' order {0, 1, 2, inf} L-norm order to use. See numpy documentation of more explanation. inf options dict Extra attack-specific options. {} Returns: Type Description ndarray of shape (n_samples,) of floats Distances to create adversarial examples.","title":"attack_distance()"},{"location":"reference/toolbox/#groot.toolbox.Model.attack_feasibility","text":"Determine whether an adversarial example is feasible for each sample given the maximum perturbation radius epsilon. Parameters: Name Type Description Default X array-like of shape (n_samples, n_features) Samples to attack. required y array-like of shape (n_samples,) True labels for the samples. required attack {\"auto\", \"milp\", \"tree\"} The attack to use, if \"auto\" the attack is chosen automatically: - \"milp\" for optimal attacks on tree ensembles using a Mixed-Integer Linear Programming formulation. - \"tree\" for optimal attacks on single decision trees by enumerating all possible paths through the tree. 'auto' order {0, 1, 2, inf} L-norm order to use. See numpy documentation of more explanation. inf epsilon float Maximum distance by which samples can move. 0.0 options dict Extra attack-specific options. {} Returns: Type Description ndarray of shape (n_samples,) of booleans Vector of True/False. Whether an adversarial example is feasible.","title":"attack_feasibility()"},{"location":"reference/toolbox/#groot.toolbox.Model.decision_function","text":"Compute prediction values for some samples. These values are the sum of leaf values in which the samples end up. Parameters: Name Type Description Default X array-like of shape (n_samples, n_features) Samples to predict. required Returns: Type Description ndarray of shape (n_samples) or ndarray of shape (n_samples, n_classes) Predicted values. Returns a 1-dimensional array if n_classes=2, else a 2-dimensional array.","title":"decision_function()"},{"location":"reference/toolbox/#groot.toolbox.Model.from_groot","text":"Create a Model instance from a GrootTree, GrootRandomForest or GROOT OneVsRestClassifier. Parameters: Name Type Description Default classifier GrootTree, GrootRandomForest or OneVsRestClassifier (of GROOT models) GROOT model to load. required Returns: Type Description Model Instantiated Model object.","title":"from_groot()"},{"location":"reference/toolbox/#groot.toolbox.Model.from_json_file","text":"Create a Model instance from a JSON file. Parameters: Name Type Description Default filename str Path to JSON file that contains a list of decision trees encoded as dicts. See the XGBoost JSON format. required n_classes int Number of classes that this model predicts. required Returns: Type Description Model Instantiated Model object.","title":"from_json_file()"},{"location":"reference/toolbox/#groot.toolbox.Model.from_provably_robust_boosting","text":"Create a Model instance from a Provably Robust Boosting TreeEnsemble. Parameters: Name Type Description Default classifier groot.provably_robust_boosting.TreeEnsemble Provably Robust Boosting model to load. required Returns: Type Description Model Instantiated Model object.","title":"from_provably_robust_boosting()"},{"location":"reference/toolbox/#groot.toolbox.Model.from_sklearn","text":"Create a Model instance from a Scikit-learn classifier. Parameters: Name Type Description Default classifier DecisionTreeClassifier, RandomForestClassifier or GradientBoostingClassifier Scikit-learn model to load. required Returns: Type Description Model Instantiated Model object.","title":"from_sklearn()"},{"location":"reference/toolbox/#groot.toolbox.Model.from_treant","text":"Create a Model instance from a TREANT decision tree. Parameters: Name Type Description Default classifier groot.treant.RobustDecisionTree TREANT model to load. required Returns: Type Description Model Instantiated Model object.","title":"from_treant()"},{"location":"reference/toolbox/#groot.toolbox.Model.predict","text":"Predict classes for some samples. The raw prediction values are turned into class labels. Parameters: Name Type Description Default X array-like of shape (n_samples, n_features) Samples to predict. required Returns: Type Description ndarray of shape (n_samples) Predicted class labels.","title":"predict()"},{"location":"reference/toolbox/#groot.toolbox.Model.to_json","text":"Export the model object to a JSON file. Parameters: Name Type Description Default filename str Name of the JSON file to export to. required indent int Number of spaces to use for indentation in the JSON file. Can be reduced to save storage. 2","title":"to_json()"},{"location":"reference/util/","text":"groot.util convert_numpy ( obj ) Convert numpy ints and floats to python types. Useful when converting objects to JSON. Parameters: Name Type Description Default obj {np.int32, np.int64, np.float32, np.float64, np.longlong} Number to convert to python int or float. required numpy_to_chensvmlight ( X , y , filename ) Export a numpy dataset to the SVM-Light format that is needed for Chen et al. (2019). The difference between SVM-Light and this format is that zero values are also included. Parameters: Name Type Description Default X array-like of shape (n_samples, n_features) Array of amples. required y array-like of shape (n_samples,) Array of class labels as integers. required filename str Exported SVM-Light dataset filename or path. required","title":"Utilities"},{"location":"reference/util/#groot.util","text":"","title":"util"},{"location":"reference/util/#groot.util.convert_numpy","text":"Convert numpy ints and floats to python types. Useful when converting objects to JSON. Parameters: Name Type Description Default obj {np.int32, np.int64, np.float32, np.float64, np.longlong} Number to convert to python int or float. required","title":"convert_numpy()"},{"location":"reference/util/#groot.util.numpy_to_chensvmlight","text":"Export a numpy dataset to the SVM-Light format that is needed for Chen et al. (2019). The difference between SVM-Light and this format is that zero values are also included. Parameters: Name Type Description Default X array-like of shape (n_samples, n_features) Array of amples. required y array-like of shape (n_samples,) Array of class labels as integers. required filename str Exported SVM-Light dataset filename or path. required","title":"numpy_to_chensvmlight()"},{"location":"reference/verification/","text":"groot.verification.kantchelian_attack KantchelianAttackWrapper ( AttackWrapper ) adversarial_examples ( self , X , y , order , options = {}) Create adversarial examples for each input sample. This method has to be overriden! Parameters: Name Type Description Default X array-like of shape (n_samples, n_features) Samples to attack. required y array-like of shape (n_samples,) True labels for the samples. required order {0, 1, 2, inf} L-norm order to use. See numpy documentation of more explanation. required options dict Extra attack-specific options. {} Returns: Type Description ndarray of shape (n_samples, n_features) Adversarial examples. attack_feasibility ( self , X , y , order , epsilon , options = {}) Determine whether an adversarial example is feasible for each sample given the maximum perturbation radius epsilon. Parameters: Name Type Description Default X array-like of shape (n_samples, n_features) Samples to attack. required y array-like of shape (n_samples,) True labels for the samples. required order {0, 1, 2, inf} L-norm order to use. See numpy documentation of more explanation. required epsilon float Maximum distance by which samples can move. required options dict Extra attack-specific options. {} Returns: Type Description ndarray of shape (n_samples,) of booleans Vector of True/False. Whether an adversarial example is feasible.","title":"Robustness verification"},{"location":"reference/verification/#groot.verification.kantchelian_attack","text":"","title":"kantchelian_attack"},{"location":"reference/verification/#groot.verification.kantchelian_attack.KantchelianAttackWrapper","text":"","title":"KantchelianAttackWrapper"},{"location":"reference/verification/#groot.verification.kantchelian_attack.KantchelianAttackWrapper.adversarial_examples","text":"Create adversarial examples for each input sample. This method has to be overriden! Parameters: Name Type Description Default X array-like of shape (n_samples, n_features) Samples to attack. required y array-like of shape (n_samples,) True labels for the samples. required order {0, 1, 2, inf} L-norm order to use. See numpy documentation of more explanation. required options dict Extra attack-specific options. {} Returns: Type Description ndarray of shape (n_samples, n_features) Adversarial examples.","title":"adversarial_examples()"},{"location":"reference/verification/#groot.verification.kantchelian_attack.KantchelianAttackWrapper.attack_feasibility","text":"Determine whether an adversarial example is feasible for each sample given the maximum perturbation radius epsilon. Parameters: Name Type Description Default X array-like of shape (n_samples, n_features) Samples to attack. required y array-like of shape (n_samples,) True labels for the samples. required order {0, 1, 2, inf} L-norm order to use. See numpy documentation of more explanation. required epsilon float Maximum distance by which samples can move. required options dict Extra attack-specific options. {} Returns: Type Description ndarray of shape (n_samples,) of booleans Vector of True/False. Whether an adversarial example is feasible.","title":"attack_feasibility()"},{"location":"reference/visualization/","text":"groot.visualization plot_adversary ( X , y , adversary , ax = None ) Plot the decision tree and samples for a 2D dataset using the adversary. Uses matplotlib. Parameters: Name Type Description Default X array-like of shape (n_samples, n_features) Feature values. required y array-like of shape (n_samples,) Class labels as integers 0 and 1. required adversary groot.adversary.DecisionTreeAdversary Adversary for this decision tree. required ax matplotlib.axes.Axes Axes object to plot on. None plot_estimator ( X , y , estimator , ax = None , steps = 100 , colors = ( 'b' , 'r' )) Plot a scikit-learn estimator and samples for a 2D dataset. Uses matplotlib. Parameters: Name Type Description Default X array-like of shape (n_samples, n_features) Feature values. required y array-like of shape (n_samples,) Ground truth targets. required estimator Scikit-learn compatible estimator Estimator to visualize required ax matplotlib.axes.Axes Axes object to plot on. None","title":"Visualization"},{"location":"reference/visualization/#groot.visualization","text":"","title":"visualization"},{"location":"reference/visualization/#groot.visualization.plot_adversary","text":"Plot the decision tree and samples for a 2D dataset using the adversary. Uses matplotlib. Parameters: Name Type Description Default X array-like of shape (n_samples, n_features) Feature values. required y array-like of shape (n_samples,) Class labels as integers 0 and 1. required adversary groot.adversary.DecisionTreeAdversary Adversary for this decision tree. required ax matplotlib.axes.Axes Axes object to plot on. None","title":"plot_adversary()"},{"location":"reference/visualization/#groot.visualization.plot_estimator","text":"Plot a scikit-learn estimator and samples for a 2D dataset. Uses matplotlib. Parameters: Name Type Description Default X array-like of shape (n_samples, n_features) Feature values. required y array-like of shape (n_samples,) Ground truth targets. required estimator Scikit-learn compatible estimator Estimator to visualize required ax matplotlib.axes.Axes Axes object to plot on. None","title":"plot_estimator()"},{"location":"reference/models/boosting/","text":"groot.provably_robust_boosting.wrapper","title":"Provably robust boosting"},{"location":"reference/models/boosting/#groot.provably_robust_boosting.wrapper","text":"","title":"wrapper"},{"location":"reference/models/groot_forest/","text":"The GrootRandomForestClassifier class uses bootstrap aggregation and partially random feature selection to train an ensemble of GrootTreeClassifier s. On datasets with many features, a GrootRandomForestClassifier might perform better than a GrootTreeClassifier as it is not limited in the number of features it can use by a maximum size. Example: from sklearn.datasets import make_moons X , y = make_moons ( random_state = 1 ) from groot.model import GrootRandomForestClassifier forest = GrootRandomForestClassifier ( attack_model = [ 0.1 , 0.1 ], random_state = 1 ) forest . fit ( X , y ) print ( forest . score ( X , y )) 1.0 groot.model.GrootRandomForestClassifier ( BaseGrootRandomForest , ClassifierMixin ) A robust random forest for binary classification. __init__ ( self , n_estimators = 100 , max_depth = None , max_features = 'sqrt' , min_samples_split = 2 , min_samples_leaf = 1 , robust_weight = 1.0 , attack_model = None , one_adversarial_class = False , verbose = False , chen_heuristic = False , max_samples = None , n_jobs = None , compile = True , random_state = None ) special Parameters: Name Type Description Default n_estimators int The number of decision trees to fit in the forest. 100 max_depth int The maximum depth for the decision trees once fitted. None max_features int or {\"sqrt\", \"log2\", None} The number of features to consider while making each split, if None then all features are considered. 'sqrt' min_samples_split int The minimum number of samples required to split a tree node. 2 min_samples_leaf int The minimum number of samples required to make a tree leaf. 1 robust_weight float The ratio of samples that are actually moved by an adversary. 1.0 attack_model array-like of shape (n_features,) Attacker capabilities for perturbing X. The attack model needs to describe for every feature in which way it can be perturbed. None one_adversarial_class bool Whether one class (malicious, 1) perturbs their samples or if both classes (benign and malicious, 0 and 1) do so. False verbose bool Whether to print fitting progress on screen. False chen_heuristic bool Whether to use the heuristic for the adversarial Gini impurity from Chen et al. (2019) instead of GROOT's adversarial Gini impurity. False max_samples float The fraction of samples to draw from X to train each decision tree. If None (default), then draw X.shape[0] samples. None n_jobs int The number of jobs to run in parallel when fitting trees. See joblib. None compile bool Whether to compile decision trees for faster predictions. True random_state int Controls the sampling of the features to consider when looking for the best split at each node. None Attributes: Name Type Description estimators_ list of GrootTree The collection of fitted sub-estimators. n_samples_ int The number of samples when fit is performed. n_features_ int The number of features when fit is performed. predict ( self , X ) Predict the classes of the input samples X. The predicted class is the rounded average of the class labels in each predicted leaf. Parameters: Name Type Description Default X array-like of shape (n_samples, n_features) The input samples to predict. required Returns: Type Description array-like of shape (n_samples,) The predicted class labels predict_proba ( self , X ) Predict class probabilities of the input samples X. The class probability is the average of the probabilities predicted by each decision tree. The probability prediction of each tree is the fraction of samples of the same class in the leaf. Parameters: Name Type Description Default X array-like of shape (n_samples, n_features) The input samples to predict. required Returns: Type Description array of shape (n_samples,) The probability for each input sample of being malicious.","title":"GROOT forest"},{"location":"reference/models/groot_forest/#groot.model.GrootRandomForestClassifier","text":"A robust random forest for binary classification.","title":"GrootRandomForestClassifier"},{"location":"reference/models/groot_forest/#groot.model.GrootRandomForestClassifier.__init__","text":"Parameters: Name Type Description Default n_estimators int The number of decision trees to fit in the forest. 100 max_depth int The maximum depth for the decision trees once fitted. None max_features int or {\"sqrt\", \"log2\", None} The number of features to consider while making each split, if None then all features are considered. 'sqrt' min_samples_split int The minimum number of samples required to split a tree node. 2 min_samples_leaf int The minimum number of samples required to make a tree leaf. 1 robust_weight float The ratio of samples that are actually moved by an adversary. 1.0 attack_model array-like of shape (n_features,) Attacker capabilities for perturbing X. The attack model needs to describe for every feature in which way it can be perturbed. None one_adversarial_class bool Whether one class (malicious, 1) perturbs their samples or if both classes (benign and malicious, 0 and 1) do so. False verbose bool Whether to print fitting progress on screen. False chen_heuristic bool Whether to use the heuristic for the adversarial Gini impurity from Chen et al. (2019) instead of GROOT's adversarial Gini impurity. False max_samples float The fraction of samples to draw from X to train each decision tree. If None (default), then draw X.shape[0] samples. None n_jobs int The number of jobs to run in parallel when fitting trees. See joblib. None compile bool Whether to compile decision trees for faster predictions. True random_state int Controls the sampling of the features to consider when looking for the best split at each node. None Attributes: Name Type Description estimators_ list of GrootTree The collection of fitted sub-estimators. n_samples_ int The number of samples when fit is performed. n_features_ int The number of features when fit is performed.","title":"__init__()"},{"location":"reference/models/groot_forest/#groot.model.GrootRandomForestClassifier.predict","text":"Predict the classes of the input samples X. The predicted class is the rounded average of the class labels in each predicted leaf. Parameters: Name Type Description Default X array-like of shape (n_samples, n_features) The input samples to predict. required Returns: Type Description array-like of shape (n_samples,) The predicted class labels","title":"predict()"},{"location":"reference/models/groot_forest/#groot.model.GrootRandomForestClassifier.predict_proba","text":"Predict class probabilities of the input samples X. The class probability is the average of the probabilities predicted by each decision tree. The probability prediction of each tree is the fraction of samples of the same class in the leaf. Parameters: Name Type Description Default X array-like of shape (n_samples, n_features) The input samples to predict. required Returns: Type Description array of shape (n_samples,) The probability for each input sample of being malicious.","title":"predict_proba()"},{"location":"reference/models/groot_tree/","text":"The main class in the GROOT repository is the GrootTreeClassifier , this class implements GROOT as a Scikit-learn compatible classifier. That means you initialize it with all important hyperparameters, then fit it using .fit(X, y) and predict with .predict(X) or .predict_proba(X) . The GrootTreeClassifier is also used within the GrootRandomForestClassifier . Example: from sklearn.datasets import make_moons X , y = make_moons ( random_state = 1 ) from groot.model import GrootTreeClassifier tree = GrootTreeClassifier ( max_depth = 3 , attack_model = [ 0.1 , 0.1 ]) tree . fit ( X , y ) print ( tree . score ( X , y )) 0.9 groot.model.GrootTreeClassifier ( BaseGrootTree , ClassifierMixin ) A robust decision tree for binary classification. __init__ ( self , max_depth = 5 , min_samples_split = 2 , min_samples_leaf = 1 , max_features = None , robust_weight = 1.0 , attack_model = None , one_adversarial_class = False , chen_heuristic = False , compile = True , random_state = None ) special Parameters: Name Type Description Default max_depth int The maximum depth for the decision tree once fitted. 5 min_samples_split int The minimum number of samples required to split a node. 2 min_samples_leaf int The minimum number of samples required to make a leaf. 1 max_features int or {\"sqrt\", \"log2\"} The number of features to consider while making each split, if None then all features are considered. None robust_weight float The ratio of samples that are actually moved by an adversary. 1.0 attack_model array-like of shape (n_features,) Attacker capabilities for perturbing X. By default, all features are considered not perturbable. None one_adversarial_class bool Whether one class (malicious, 1) perturbs their samples or if both classes (benign and malicious, 0 and 1) do so. False chen_heuristic bool Whether to use the heuristic for the adversarial Gini impurity from Chen et al. (2019) instead of GROOT's adversarial Gini impurity. False compile bool Whether to compile the tree for faster predictions. True random_state int Controls the sampling of the features to consider when looking for the best split at each node. None Attributes: Name Type Description classes_ ndarray of shape (n_classes,) The class labels. max_features_ int The inferred value of max_features. n_samples_ int The number of samples when fit is performed. n_features_ int The number of features when fit is performed. root_ Node The root node of the tree after fitting. compiled_root_ CompiledTree The compiled root node of the tree after fitting. predict ( self , X ) Predict the classes of the input samples X. The predicted class is the most frequently occuring class label in a leaf. Parameters: Name Type Description Default X array-like of shape (n_samples, n_features) The input samples to predict. required Returns: Type Description array-like of shape (n_samples,) The predicted class labels predict_proba ( self , X ) Predict class probabilities of the input samples X. The class probability is the fraction of samples of the same class in the leaf. Parameters: Name Type Description Default X array-like of shape (n_samples, n_features) The input samples to predict. required Returns: Type Description array of shape (n_samples,) The probability for each input sample of being malicious.","title":"GROOT tree"},{"location":"reference/models/groot_tree/#groot.model.GrootTreeClassifier","text":"A robust decision tree for binary classification.","title":"GrootTreeClassifier"},{"location":"reference/models/groot_tree/#groot.model.GrootTreeClassifier.__init__","text":"Parameters: Name Type Description Default max_depth int The maximum depth for the decision tree once fitted. 5 min_samples_split int The minimum number of samples required to split a node. 2 min_samples_leaf int The minimum number of samples required to make a leaf. 1 max_features int or {\"sqrt\", \"log2\"} The number of features to consider while making each split, if None then all features are considered. None robust_weight float The ratio of samples that are actually moved by an adversary. 1.0 attack_model array-like of shape (n_features,) Attacker capabilities for perturbing X. By default, all features are considered not perturbable. None one_adversarial_class bool Whether one class (malicious, 1) perturbs their samples or if both classes (benign and malicious, 0 and 1) do so. False chen_heuristic bool Whether to use the heuristic for the adversarial Gini impurity from Chen et al. (2019) instead of GROOT's adversarial Gini impurity. False compile bool Whether to compile the tree for faster predictions. True random_state int Controls the sampling of the features to consider when looking for the best split at each node. None Attributes: Name Type Description classes_ ndarray of shape (n_classes,) The class labels. max_features_ int The inferred value of max_features. n_samples_ int The number of samples when fit is performed. n_features_ int The number of features when fit is performed. root_ Node The root node of the tree after fitting. compiled_root_ CompiledTree The compiled root node of the tree after fitting.","title":"__init__()"},{"location":"reference/models/groot_tree/#groot.model.GrootTreeClassifier.predict","text":"Predict the classes of the input samples X. The predicted class is the most frequently occuring class label in a leaf. Parameters: Name Type Description Default X array-like of shape (n_samples, n_features) The input samples to predict. required Returns: Type Description array-like of shape (n_samples,) The predicted class labels","title":"predict()"},{"location":"reference/models/groot_tree/#groot.model.GrootTreeClassifier.predict_proba","text":"Predict class probabilities of the input samples X. The class probability is the fraction of samples of the same class in the leaf. Parameters: Name Type Description Default X array-like of shape (n_samples, n_features) The input samples to predict. required Returns: Type Description array of shape (n_samples,) The probability for each input sample of being malicious.","title":"predict_proba()"},{"location":"reference/models/treant/","text":"groot.treant Created by Gabriele Tolomei on 2019-01-23. Code adapted for comparison with GROOT from src/parallel_robust_forest.py at https://github.com/gtolomei/treant Also see: https://arxiv.org/abs/1907.01197 Attacker Class Attacker represents an attacker. __init__ ( self , rules , budget ) special Class constructor. Parameters: Name Type Description Default rules obj: AttackerRule ): set of AttackerRule objects. required budget float total budget of the attacker (per instance). required attack ( self , x , feature_id , cost ) This function retrieves the list of attacks to a given instance, on a given feature, subject to a given cost. attack_dataset ( self , X , attacks_filename = None ) This function is responsible for attacking the whole input dataset. It either loads all the attacks from the attack file provided as input or it computes all the attacks from scratch. AttackerRule Class AttackerRule represents a rule of attack. __init__ ( self , pre_conditions , post_condition , cost , is_numerical = True ) special Class constructor. Parameters: Name Type Description Default pre_conditions dict set of pre-conditions which must be met in order for this rule to be applied. required post_condition dict post-condition indicating the outcome of this rule once applied. required cost float cost of rule application. required is_numerical boolean flag to indicate whether the attack specified by this rule operates on a numerical (perturbation) or a categorical (assignment) feature. True apply ( self , x ) Application of the rule to the input instance x. Parameters: Name Type Description Default x numpy.array 1-dimensional array representing an instance. required Returns: Type Description x_prime (numpy.array) A (deep) copy of x yet modified according to the post-condition of this rule. get_cost ( self ) Return the cost of this rule. get_target_feature ( self ) Return the feature (id) targeted by this rule. is_applicable ( self , x ) Returns whether the rule can be applied to the input instance x or not. Parameters: Name Type Description Default x numpy.array 1-dimensional array representing an instance. required numerical_idx list binary array which indicates whether a feature is numerical or not; numerical_idx[i] = 1 iff feature id i is numerical, 0 otherwise. required Returns: Type Description True iff this rule is applicable to x (i.e., if x satisfies ALL the pre-conditions of this rule). Constraint Class Constraint represents a constraint. __init__ ( self , x , y , cost , ineq , bound ) special Class constructor. Parameters: Name Type Description Default x int current instance. required y int/float label associated with this instance. required cost float cost associated with this instance (so far). required ineq int flag to encode the direction of the inequality represented by this constraint; 0 = 'less than', 1 = 'greater than or equal to'. required bound float constraint value on the loss function required encode_for_optimizer ( self , direction ) Encode this constraint according to the format used by the optimizer. propagate_left ( self , attacker , feature_id , feature_value , is_numerical ) Propagate the constraint to the left. propagate_right ( self , attacker , feature_id , feature_value , is_numerical ) Propagate the constraint to the right. Node Class Node represents a node of a decision tree. __init__ ( self , node_id , values , n_values , left = None , right = None , best_split_feature_id = None , best_split_feature_value = None ) special Class constructor. Parameters: Name Type Description Default node_id int node identifier. required values int number of instances required n_values int maximum number of unique y values. required left obj: Node , optional): left child node. Defaults to None. None right obj: Node , optional): left child node. Defaults to None. None best_split_feature_id int index of the feature associated with the best split of this Node. Defaults to None. None best_split_feature_value float value of the feature associated with the best split of this Node. Defaults to None. None get_node_prediction ( self ) Get the prediction as being computed at this node. is_leaf ( self ) Returns True iff the current node is a leaf (i.e., if it doesn't have neither a left nor a right child) RobustDecisionTree ( BaseEstimator , ClassifierMixin ) This class implements a single Robust Decision Tree. Inspired by sklearn API, it is a sublcass of the sklearn.base.BaseEstimator class and exposes two main methods: - fit(X, y) - predict(X) The former is used at training time for learning a single decision tree; the latter is used at inference (testing) time for computing predictions using the learned tree. __init__ ( self , tree_id = 0 , attacker =< groot . treant . Attacker object at 0x7f5e8ea0f7f0 > , split_optimizer =< groot . treant . SplitOptimizer object at 0x7f5e8ea0f850 > , max_depth = 8 , min_instances_per_node = 20 , max_samples = 1.0 , max_features = 1.0 , replace_samples = False , replace_features = False , feature_blacklist = {}, affine = True , seed = 0 ) special Class constructor. Parameters: Name Type Description Default tree_id int tree identifier. 0 attacker obj: Attacker ): the attacker under which this tree must grow (default = empty attacker). <groot.treant.Attacker object at 0x7f5e8ea0f7f0> split_optimizer obj: SplitOptimizer ): the optimizer used by this tree (default = SSE). <groot.treant.SplitOptimizer object at 0x7f5e8ea0f850> max_depth int maximum depth of the tree to be generated (default = 10). 8 min_instances_per_node int minimum number of instances per node (default = 20). 20 max_samples float proportion of instances sampled without replacement (default = 1.0, i.e., 100%) 1.0 max_features float proportion of features sampled without replacement (default = 1.0, i.e., 100%) 1.0 feature_blacklist dict dictionary of features excluded during tree growth (default = {}), i.e., empty). {} replace_samples bool whether the random sampling of instances should be with replacement or not (default = False). False replace_features bool whether the random sampling of features should be with replacement or not (default = False). False seed int integer used by randomized processes. 0 fit ( self , X , y = None , numerical_idx = None ) This function is the public API's entry point for client code to start training a single Robust Decision Tree. It saves both the input data (X) and labels/targets (y) in the internals of the tree and delegates off to the private self.__fit method. The result being a reference to the root node of the trained tree. Parameters: Name Type Description Default X numpy.array 2-dimensional array of shape (n_samples, n_features) required y numpy.array 1-dimensional array of values of shape (n_samples, ) None predict ( self , X , y = None ) This function is the public API's entry point for client code to obtain predictions from an already trained tree. If this tree hasn't been trained yet, predictions cannot be made; otherwise, for each instance in X, the tree is traversed until a leaf node is met: the prediction stored at that leaf node is the one returned to the caller. Parameters: Name Type Description Default X numpy.array 2-dimensional array of shape (n_test_samples, n_features) containing samples which we want to know the predictions of. required Returns: Type Description predictions (numpy.array) 1-dimensional array of shape (n_test_samples, ). predict_proba ( self , X , y = None ) This function is the public API's entry point for client code to obtain predictions from an already trained tree. If this tree hasn't been trained yet, predictions cannot be made; otherwise, for each instance in X, the tree is traversed until a leaf node is met: the prediction stored at that leaf node is the one returned to the caller. Parameters: Name Type Description Default X numpy.array 2-dimensional array of shape (n_test_samples, n_features) containing samples which we want to know the predictions of. required Returns: Type Description probs (numpy.array) 2-dimensional array of shape (n_test_samples, 2) containing probability scores both for class 0 (1st column) and class 1 (2nd column). save ( self , filename ) This function is used to persist this RobustDecisionTree object to file on disk using dill. SplitOptimizer Class used for determining the best splitting strategy, accoriding to a specific splitting function. The class comes with few splitting functions already implemented. In particular, those are as follows: __gini_impurity (classification); __entropy (classification); __logloss (classificattion); __mse (regression); __sse (regression); __mae (regression). Of course this class can be instantiated with custom, user-defined splitting functions. __init__ ( self , split_function_name = None , icml2019 = False ) special Class constructor. Parameters: Name Type Description Default split_function func The function used as splitting criterion. Defaults to None, if so it falls back to __gini_impurity implemented internally. required if split_function is None: self.split_function = SplitOptimizer._SplitOptimizer__sse self.split_function_name = \"SSE\" !!! else self.split_function = split_function if split_function_name is None: split_function_name = split_function. name self.split_function_name = split_function_name evaluate_split ( self , y_true , y_pred ) This function is a meta-function which calls off to the actual splitting function along with input arguments. optimize_gain ( self , X , y , rows , numerical_idx , feature_blacklist , n_sample_features , replace_features , attacker , costs , constraints , current_score , current_prediction_score ) This function is responsible for finding the splitting which optimizes the gain (according to the splitting function) among all the possibile splittings. Parameters: Name Type Description Default X numpy.array 2-dimensional array of shape (n_samples, n_features) representing the feature matrix; required y numpy.array 1-dimensional array of shape (n_samples, ) representing class labels (classification) or target values (regression). required rows numpy.array 1-dimensional array containing the indices of a subset of n_samples (i.e., a subset of the rows of X and y). required numerical_idx list binary array which indicates whether a feature is numerical or not; numerical_idx[i] = 1 iff feature id i is numerical, 0 otherwise. required feature_blacklist set set of (integer) indices corresponding to blacklisted features. required n_sample_features int number of features to be randomly sampled at each node split. required attacker obj: Attacker ): attacker. required costs dict cost associated with each instance (indexed by rows). required constraints list list of Constraint objects. required current_score float is the score before any splitting is done; this must be compared with the best splitting found. Whenever the current_score is greater than the one computed after splitting there will be a gain. required Returns: Type Description best_gain (float) The highest gain obtained after all the possible splittings have been tested (may be 0, in which case the splitting will be not worth it) best_split_left_id (numpy.array): 1-dimensional array containing all the indices of rows going on the left branch. best_split_right_id (numpy.array): 1-dimensional array containing all the indices of rows going on the right branch. best_split_feature_id (int): index of the feature which led to the best splitting. best_split_feature_value (int/float): value of the feature which led to the best splitting. next_best_split_feature_value (int/float): next-observed value of the feature which led to the best splitting. constraints_left (numpy.array): array of constraints if propagated to left. constraints_right (numpy.array): array of constraints if propagated to right. costs_left (numpy.array): array of costs if propagated left. costs_right (numpy.array): array of cost if propagated right.","title":"TREANT"},{"location":"reference/models/treant/#groot.treant","text":"Created by Gabriele Tolomei on 2019-01-23. Code adapted for comparison with GROOT from src/parallel_robust_forest.py at https://github.com/gtolomei/treant Also see: https://arxiv.org/abs/1907.01197","title":"treant"},{"location":"reference/models/treant/#groot.treant.Attacker","text":"Class Attacker represents an attacker.","title":"Attacker"},{"location":"reference/models/treant/#groot.treant.Attacker.__init__","text":"Class constructor. Parameters: Name Type Description Default rules obj: AttackerRule ): set of AttackerRule objects. required budget float total budget of the attacker (per instance). required","title":"__init__()"},{"location":"reference/models/treant/#groot.treant.Attacker.attack","text":"This function retrieves the list of attacks to a given instance, on a given feature, subject to a given cost.","title":"attack()"},{"location":"reference/models/treant/#groot.treant.Attacker.attack_dataset","text":"This function is responsible for attacking the whole input dataset. It either loads all the attacks from the attack file provided as input or it computes all the attacks from scratch.","title":"attack_dataset()"},{"location":"reference/models/treant/#groot.treant.AttackerRule","text":"Class AttackerRule represents a rule of attack.","title":"AttackerRule"},{"location":"reference/models/treant/#groot.treant.AttackerRule.__init__","text":"Class constructor. Parameters: Name Type Description Default pre_conditions dict set of pre-conditions which must be met in order for this rule to be applied. required post_condition dict post-condition indicating the outcome of this rule once applied. required cost float cost of rule application. required is_numerical boolean flag to indicate whether the attack specified by this rule operates on a numerical (perturbation) or a categorical (assignment) feature. True","title":"__init__()"},{"location":"reference/models/treant/#groot.treant.AttackerRule.apply","text":"Application of the rule to the input instance x. Parameters: Name Type Description Default x numpy.array 1-dimensional array representing an instance. required Returns: Type Description x_prime (numpy.array) A (deep) copy of x yet modified according to the post-condition of this rule.","title":"apply()"},{"location":"reference/models/treant/#groot.treant.AttackerRule.get_cost","text":"Return the cost of this rule.","title":"get_cost()"},{"location":"reference/models/treant/#groot.treant.AttackerRule.get_target_feature","text":"Return the feature (id) targeted by this rule.","title":"get_target_feature()"},{"location":"reference/models/treant/#groot.treant.AttackerRule.is_applicable","text":"Returns whether the rule can be applied to the input instance x or not. Parameters: Name Type Description Default x numpy.array 1-dimensional array representing an instance. required numerical_idx list binary array which indicates whether a feature is numerical or not; numerical_idx[i] = 1 iff feature id i is numerical, 0 otherwise. required Returns: Type Description True iff this rule is applicable to x (i.e., if x satisfies ALL the pre-conditions of this rule).","title":"is_applicable()"},{"location":"reference/models/treant/#groot.treant.Constraint","text":"Class Constraint represents a constraint.","title":"Constraint"},{"location":"reference/models/treant/#groot.treant.Constraint.__init__","text":"Class constructor. Parameters: Name Type Description Default x int current instance. required y int/float label associated with this instance. required cost float cost associated with this instance (so far). required ineq int flag to encode the direction of the inequality represented by this constraint; 0 = 'less than', 1 = 'greater than or equal to'. required bound float constraint value on the loss function required","title":"__init__()"},{"location":"reference/models/treant/#groot.treant.Constraint.encode_for_optimizer","text":"Encode this constraint according to the format used by the optimizer.","title":"encode_for_optimizer()"},{"location":"reference/models/treant/#groot.treant.Constraint.propagate_left","text":"Propagate the constraint to the left.","title":"propagate_left()"},{"location":"reference/models/treant/#groot.treant.Constraint.propagate_right","text":"Propagate the constraint to the right.","title":"propagate_right()"},{"location":"reference/models/treant/#groot.treant.Node","text":"Class Node represents a node of a decision tree.","title":"Node"},{"location":"reference/models/treant/#groot.treant.Node.__init__","text":"Class constructor. Parameters: Name Type Description Default node_id int node identifier. required values int number of instances required n_values int maximum number of unique y values. required left obj: Node , optional): left child node. Defaults to None. None right obj: Node , optional): left child node. Defaults to None. None best_split_feature_id int index of the feature associated with the best split of this Node. Defaults to None. None best_split_feature_value float value of the feature associated with the best split of this Node. Defaults to None. None","title":"__init__()"},{"location":"reference/models/treant/#groot.treant.Node.get_node_prediction","text":"Get the prediction as being computed at this node.","title":"get_node_prediction()"},{"location":"reference/models/treant/#groot.treant.Node.is_leaf","text":"Returns True iff the current node is a leaf (i.e., if it doesn't have neither a left nor a right child)","title":"is_leaf()"},{"location":"reference/models/treant/#groot.treant.RobustDecisionTree","text":"This class implements a single Robust Decision Tree. Inspired by sklearn API, it is a sublcass of the sklearn.base.BaseEstimator class and exposes two main methods: - fit(X, y) - predict(X) The former is used at training time for learning a single decision tree; the latter is used at inference (testing) time for computing predictions using the learned tree.","title":"RobustDecisionTree"},{"location":"reference/models/treant/#groot.treant.RobustDecisionTree.__init__","text":"Class constructor. Parameters: Name Type Description Default tree_id int tree identifier. 0 attacker obj: Attacker ): the attacker under which this tree must grow (default = empty attacker). <groot.treant.Attacker object at 0x7f5e8ea0f7f0> split_optimizer obj: SplitOptimizer ): the optimizer used by this tree (default = SSE). <groot.treant.SplitOptimizer object at 0x7f5e8ea0f850> max_depth int maximum depth of the tree to be generated (default = 10). 8 min_instances_per_node int minimum number of instances per node (default = 20). 20 max_samples float proportion of instances sampled without replacement (default = 1.0, i.e., 100%) 1.0 max_features float proportion of features sampled without replacement (default = 1.0, i.e., 100%) 1.0 feature_blacklist dict dictionary of features excluded during tree growth (default = {}), i.e., empty). {} replace_samples bool whether the random sampling of instances should be with replacement or not (default = False). False replace_features bool whether the random sampling of features should be with replacement or not (default = False). False seed int integer used by randomized processes. 0","title":"__init__()"},{"location":"reference/models/treant/#groot.treant.RobustDecisionTree.fit","text":"This function is the public API's entry point for client code to start training a single Robust Decision Tree. It saves both the input data (X) and labels/targets (y) in the internals of the tree and delegates off to the private self.__fit method. The result being a reference to the root node of the trained tree. Parameters: Name Type Description Default X numpy.array 2-dimensional array of shape (n_samples, n_features) required y numpy.array 1-dimensional array of values of shape (n_samples, ) None","title":"fit()"},{"location":"reference/models/treant/#groot.treant.RobustDecisionTree.predict","text":"This function is the public API's entry point for client code to obtain predictions from an already trained tree. If this tree hasn't been trained yet, predictions cannot be made; otherwise, for each instance in X, the tree is traversed until a leaf node is met: the prediction stored at that leaf node is the one returned to the caller. Parameters: Name Type Description Default X numpy.array 2-dimensional array of shape (n_test_samples, n_features) containing samples which we want to know the predictions of. required Returns: Type Description predictions (numpy.array) 1-dimensional array of shape (n_test_samples, ).","title":"predict()"},{"location":"reference/models/treant/#groot.treant.RobustDecisionTree.predict_proba","text":"This function is the public API's entry point for client code to obtain predictions from an already trained tree. If this tree hasn't been trained yet, predictions cannot be made; otherwise, for each instance in X, the tree is traversed until a leaf node is met: the prediction stored at that leaf node is the one returned to the caller. Parameters: Name Type Description Default X numpy.array 2-dimensional array of shape (n_test_samples, n_features) containing samples which we want to know the predictions of. required Returns: Type Description probs (numpy.array) 2-dimensional array of shape (n_test_samples, 2) containing probability scores both for class 0 (1st column) and class 1 (2nd column).","title":"predict_proba()"},{"location":"reference/models/treant/#groot.treant.RobustDecisionTree.save","text":"This function is used to persist this RobustDecisionTree object to file on disk using dill.","title":"save()"},{"location":"reference/models/treant/#groot.treant.SplitOptimizer","text":"Class used for determining the best splitting strategy, accoriding to a specific splitting function. The class comes with few splitting functions already implemented. In particular, those are as follows: __gini_impurity (classification); __entropy (classification); __logloss (classificattion); __mse (regression); __sse (regression); __mae (regression). Of course this class can be instantiated with custom, user-defined splitting functions.","title":"SplitOptimizer"},{"location":"reference/models/treant/#groot.treant.SplitOptimizer.__init__","text":"Class constructor. Parameters: Name Type Description Default split_function func The function used as splitting criterion. Defaults to None, if so it falls back to __gini_impurity implemented internally. required if split_function is None: self.split_function = SplitOptimizer._SplitOptimizer__sse self.split_function_name = \"SSE\" !!! else self.split_function = split_function if split_function_name is None: split_function_name = split_function. name self.split_function_name = split_function_name","title":"__init__()"},{"location":"reference/models/treant/#groot.treant.SplitOptimizer.evaluate_split","text":"This function is a meta-function which calls off to the actual splitting function along with input arguments.","title":"evaluate_split()"},{"location":"reference/models/treant/#groot.treant.SplitOptimizer.optimize_gain","text":"This function is responsible for finding the splitting which optimizes the gain (according to the splitting function) among all the possibile splittings. Parameters: Name Type Description Default X numpy.array 2-dimensional array of shape (n_samples, n_features) representing the feature matrix; required y numpy.array 1-dimensional array of shape (n_samples, ) representing class labels (classification) or target values (regression). required rows numpy.array 1-dimensional array containing the indices of a subset of n_samples (i.e., a subset of the rows of X and y). required numerical_idx list binary array which indicates whether a feature is numerical or not; numerical_idx[i] = 1 iff feature id i is numerical, 0 otherwise. required feature_blacklist set set of (integer) indices corresponding to blacklisted features. required n_sample_features int number of features to be randomly sampled at each node split. required attacker obj: Attacker ): attacker. required costs dict cost associated with each instance (indexed by rows). required constraints list list of Constraint objects. required current_score float is the score before any splitting is done; this must be compared with the best splitting found. Whenever the current_score is greater than the one computed after splitting there will be a gain. required Returns: Type Description best_gain (float) The highest gain obtained after all the possible splittings have been tested (may be 0, in which case the splitting will be not worth it) best_split_left_id (numpy.array): 1-dimensional array containing all the indices of rows going on the left branch. best_split_right_id (numpy.array): 1-dimensional array containing all the indices of rows going on the right branch. best_split_feature_id (int): index of the feature which led to the best splitting. best_split_feature_value (int/float): value of the feature which led to the best splitting. next_best_split_feature_value (int/float): next-observed value of the feature which led to the best splitting. constraints_left (numpy.array): array of constraints if propagated to left. constraints_right (numpy.array): array of constraints if propagated to right. costs_left (numpy.array): array of costs if propagated left. costs_right (numpy.array): array of cost if propagated right.","title":"optimize_gain()"}]}